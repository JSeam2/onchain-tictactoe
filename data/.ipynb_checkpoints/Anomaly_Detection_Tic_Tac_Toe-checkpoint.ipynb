{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tic Tac Toe Verifier\n",
        "\n",
        "We create an ML model that verifies TicTacToe Games\n",
        "\n",
        "Make sure to use a GPU otherwise you'll take a super long time to train"
      ],
      "metadata": {
        "id": "wKP_h_Q61LZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbmq0MNjU3-g",
        "outputId": "7d12599f-530d-4971-a625-02fe42a6f11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate legal game states and illegal game states\n",
        "\n",
        "1. Recursively lookup all the possible tictactoe game states and create a legal dataset\n",
        "2. Use the legal dataset and permute illegal game states"
      ],
      "metadata": {
        "id": "gZawMT3tcHvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def check_winner(board):\n",
        "    winning_combinations = [\n",
        "        [0, 1, 2], [3, 4, 5], [6, 7, 8],  # rows\n",
        "        [0, 3, 6], [1, 4, 7], [2, 5, 8],  # columns\n",
        "        [0, 4, 8], [2, 4, 6]              # diagonals\n",
        "    ]\n",
        "    for combo in winning_combinations:\n",
        "        if board[combo[0]] == board[combo[1]] == board[combo[2]] and board[combo[0]] is not None:\n",
        "            return board[combo[0]]\n",
        "    return None\n",
        "\n",
        "def generate_games(board, player):\n",
        "    winner = check_winner(board)\n",
        "    if winner or None not in board:\n",
        "        # Game is over, save the outcome and board state\n",
        "        return [{\n",
        "            \"history\": [list(board)],\n",
        "            \"outcome\": winner if winner else \"Draw\"\n",
        "        }]\n",
        "\n",
        "    games = []\n",
        "    for i in range(9):\n",
        "        if board[i] is None:\n",
        "            new_board = board.copy()\n",
        "            new_board[i] = player\n",
        "            next_player = 'O' if player == 'X' else 'X'\n",
        "            next_games = generate_games(new_board, next_player)\n",
        "            for game in next_games:\n",
        "                game[\"history\"].insert(0, list(board))\n",
        "            games.extend(next_games)\n",
        "\n",
        "    return games\n",
        "\n",
        "def generate_illegal_games(games):\n",
        "    illegal_games = []\n",
        "    for game in games:\n",
        "        history = game['history']\n",
        "        illegal_history = []\n",
        "        for round in history:\n",
        "            round_list = []\n",
        "            for item in round:\n",
        "                # cycle the permutations\n",
        "                if item is None:\n",
        "                    round_list.append(\"X\")\n",
        "                if item == \"X\":\n",
        "                    round_list.append(\"O\")\n",
        "                if item == \"O\":\n",
        "                    round_list.append(None)\n",
        "            illegal_history.append(round_list)\n",
        "        illegal_games.append({\n",
        "            \"history\": illegal_history,\n",
        "            \"outcome\": game[\"outcome\"]\n",
        "        })\n",
        "    return illegal_games\n",
        "\n",
        "\n",
        "\n",
        "initial_board = [None for _ in range(9)]\n",
        "games = generate_games(initial_board, 'X')\n",
        "illegal_games = generate_illegal_games(games)\n",
        "\n",
        "with open(\"tic_tac_toe_games_good.json\", \"w\") as file:\n",
        "    file.write(\"[\\n\")  # Start of the list\n",
        "    for i, game in enumerate(games):\n",
        "        json.dump(game, file, separators=(',', ': '))\n",
        "        if i != len(games) - 1:  # If it's not the last game, add a comma\n",
        "            file.write(\",\\n\")\n",
        "        else:\n",
        "            file.write(\"\\n\")\n",
        "    file.write(\"]\\n\")\n",
        "\n",
        "with open(\"tic_tac_toe_games_bad.json\", \"w\") as file:\n",
        "    file.write(\"[\\n\")  # Start of the list\n",
        "    for i, game in enumerate(illegal_games):\n",
        "        json.dump(game, file, separators=(',', ': '))\n",
        "        if i != len(illegal_games) - 1:  # If it's not the last game, add a comma\n",
        "            file.write(\",\\n\")\n",
        "        else:\n",
        "            file.write(\"\\n\")\n",
        "    file.write(\"]\\n\")\n"
      ],
      "metadata": {
        "id": "vd-XNueUcG-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the Anomaly Detection Model\n",
        "1. Create a variational autoencoder, as the state space is small enough put the game history into an input matrix\n",
        "\n",
        "2. Fully connect the final outputs and use two outputs to represent true or false"
      ],
      "metadata": {
        "id": "0FTtqoHs13Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, IterableDataset, random_split\n",
        "import torch.optim as optim\n",
        "import json\n",
        "\n",
        "\n",
        "class TicTacToeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TicTacToeNet, self).__init__()\n",
        "\n",
        "        # Fully connected layers\n",
        "        # 9 possible inputs x 10 rounds + 1 final output value\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=91,\n",
        "            out_channels=16,\n",
        "            kernel_size=3,\n",
        "            padding=1)\n",
        "        self.batchnorm2d = nn.BatchNorm2d(\n",
        "            num_features=16\n",
        "        )\n",
        "        self.fc1 = nn.Linear(16, 3)\n",
        "        self.fc2 = nn.Linear(3, 16)\n",
        "        self.fc3 = nn.Linear(16, 91)\n",
        "        self.fc4 = nn.Linear(91, 2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through fully connected layers with ReLU activation\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm2d(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "_yV7ou8B1LDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load all possible tictactoe games"
      ],
      "metadata": {
        "id": "Qnf8wZk3nnou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class JsonDataset(IterableDataset):\n",
        "    def __init__(self, file_good, file_bad):\n",
        "        self.file_good = file_good\n",
        "        self.file_bad = file_bad\n",
        "        self.data = self.load_data()\n",
        "\n",
        "\n",
        "\n",
        "    def parse_json_object(self, line):\n",
        "        try:\n",
        "            return json.loads(line)\n",
        "        except json.JSONDecodeError:\n",
        "            return None\n",
        "\n",
        "    def encode_board(self, board):\n",
        "        encoding = []\n",
        "        for cell in board:\n",
        "            if cell == 'X':\n",
        "                encoding.extend([0])\n",
        "            elif cell == 'O':\n",
        "                encoding.extend([1])\n",
        "            else:\n",
        "                encoding.extend([2])\n",
        "\n",
        "        return encoding\n",
        "\n",
        "\n",
        "    def encode_outcome(self, outcome):\n",
        "        if outcome == 'X':\n",
        "            return 0\n",
        "        elif outcome == 'O':\n",
        "            return 1\n",
        "        else:\n",
        "            return 2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        padded_history, sample_outcome = self.data[idx]\n",
        "        return torch.tensor(padded_history, dtype=torch.float), torch.tensor(sample_outcome, dtype=torch.long)\n",
        "\n",
        "\n",
        "    def load_data(self):\n",
        "        data = []\n",
        "        with open(self.file_good, 'r') as f:\n",
        "            # Skip the first line (which is \"[\")\n",
        "            next(f)\n",
        "            for line in f:\n",
        "                # Remove the trailing comma for all lines except the last one (which is \"]\")\n",
        "                if line.endswith(\",\\n\"):\n",
        "                    line = line[:-2]\n",
        "                sample = self.parse_json_object(line)\n",
        "                if sample is not None:\n",
        "                    max_length = 10  # Maximum length of a Tic Tac Toe game\n",
        "                    history = sample['history']\n",
        "\n",
        "                    if len(history) == max_length:\n",
        "                        padded_history = history\n",
        "                    else:\n",
        "                        padded_history = history + [[None] * 9 for _ in range(max_length - len(history))]\n",
        "\n",
        "                    padded_history = [self.encode_board(x) for x in padded_history]\n",
        "                    sample_outcome = self.encode_outcome(sample['outcome'])\n",
        "\n",
        "                    padded_history.extend([sample_outcome])\n",
        "\n",
        "                    data.append((padded_history, 0))\n",
        "\n",
        "                    print(data)\n",
        "\n",
        "\n",
        "        with open(self.file_bad, 'r') as f:\n",
        "            # Skip the first line (which is \"[\")\n",
        "            next(f)\n",
        "            for line in f:\n",
        "                # Remove the trailing comma for all lines except the last one (which is \"]\")\n",
        "                if line.endswith(\",\\n\"):\n",
        "                    line = line[:-2]\n",
        "                sample = self.parse_json_object(line)\n",
        "                if sample is not None:\n",
        "                    max_length = 10  # Maximum length of a Tic Tac Toe game\n",
        "                    history = sample['history']\n",
        "\n",
        "                    if len(history) == max_length:\n",
        "                        padded_history = history\n",
        "                    else:\n",
        "                        padded_history = history + [[None] * 9 for _ in range(max_length - len(history))]\n",
        "\n",
        "                    padded_history = [self.encode_board(x) for x in padded_history]\n",
        "                    sample_outcome = self.encode_outcome(sample['outcome'])\n",
        "\n",
        "                    padded_history.extend([sample_outcome])\n",
        "\n",
        "                    data.append((padded_history, 1))\n",
        "\n",
        "                    print(data)\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "dataset = JsonDataset('tic_tac_toe_games_good.json', 'tic_tac_toe_games_bad.json')  # Add other files as necessary\n",
        "\n",
        "total_size = len(dataset)\n",
        "print(total_size)\n",
        "train_size = int(0.8 * total_size)\n",
        "test_size = total_size - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "Sw19C2VxZpS9",
        "outputId": "d4caf07a-c297-4296-9350-507cafca2e38"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-55124b53139f>\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJsonDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tic_tac_toe_games_good.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tic_tac_toe_games_bad.json'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add other files as necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-55124b53139f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_good, file_bad)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_good\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_good\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_bad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_bad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-55124b53139f>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "wgJSPAMLuM-u",
        "outputId": "3623ca87-c6c3-458a-95a7-a83e1a901e81"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-68e2354fc364>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-5a07ef7c787b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mpadded_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_outcome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: not a sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "A6VBZchsnx2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model = TicTacToeNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "MAX_EPOCH = 5\n",
        "\n",
        "for epoch in range(MAX_EPOCH):\n",
        "    model.train()\n",
        "    for data, valid in train_loader:\n",
        "        print(data)\n",
        "        print(valid)\n",
        "        history = history.to(device)  # Move history to CUDA\n",
        "        outcome = outcome.to(device)  # Move outcome to CUDA\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "\n",
        "        loss = criterion(outputs, valid)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for data, valid in test_loader:\n",
        "\n",
        "            history = history.to(device)  # Move history to CUDA\n",
        "            outcome = outcome.to(device)  # Move outcome to CUDA\n",
        "            outputs = model(data)\n",
        "\n",
        "            # Get the predicted class (the index of the maximum value in the output tensor)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "            total_predictions += outcome.size(0)\n",
        "            correct_predictions += (predicted == outcome).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct_predictions / total_predictions\n",
        "    print(f\"Epoch {epoch + 1}/{MAX_EPOCH} - Accuracy: {accuracy:.2f}%\")\n",
        "    print(history[0])\n",
        "    print(outcome[0])"
      ],
      "metadata": {
        "id": "NE1QPy_91z_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "df2da524-eeb5-45d9-c3cc-b6e83450c715"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-de55c4044ff6>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-5a07ef7c787b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mpadded_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_outcome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: not a sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Onnx and Data out for the Hub"
      ],
      "metadata": {
        "id": "mLEdsCI2od7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the CPU\n",
        "model = model.cpu()\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Obtain a sample datapoint from the DataLoader\n",
        "sample_data_iter = iter(train_loader)\n",
        "sample_history, _ = next(sample_data_iter)\n",
        "\n",
        "# No need to move the sample to the device since everything is on the CPU now\n",
        "x = sample_history\n",
        "print(x)\n",
        "\n",
        "# Export the model using ONNX\n",
        "torch.onnx.export(\n",
        "    model,                        # model being run\n",
        "    x,                            # model input (or a tuple for multiple inputs)\n",
        "    \"tictactoe_network.onnx\",     # where to save the model (can be a file or file-like object)\n",
        "    export_params=True,           # store the trained parameter weights inside the model file\n",
        "    opset_version=10,             # the ONNX version to export the model to\n",
        "    do_constant_folding=True,     # whether to execute constant folding for optimization\n",
        "    input_names=['input'],        # the model's input names\n",
        "    output_names=['output'],      # the model's output names\n",
        "    dynamic_axes={\n",
        "        'input': {0: 'batch_size'},     # variable length axes\n",
        "        'output': {0: 'batch_size'}\n",
        "    }\n",
        ")\n",
        "\n",
        "data_array = ((x[-1]).detach().numpy()).reshape([-1]).tolist()\n",
        "\n",
        "data = dict(input_data = [data_array])\n",
        "\n",
        "print(data)\n",
        "\n",
        "    # Serialize data into file:\n",
        "json.dump(data, open(\"data.json\", 'w'))\n",
        "\n",
        "\n",
        "# use the test set to calibrate the circuit\n",
        "cal_data = dict(input_data = x.flatten().tolist())\n",
        "\n",
        "# Serialize calibration data into file:\n",
        "json.dump(data, open(\"cal_data.json\", 'w'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb4hgLGanF9J",
        "outputId": "d533aeac-4079-4bfd-cc05-4a2b1678b547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 1., 2., 0., 1., 0., 0., 1.],\n",
            "        [2., 1., 0., 0., 0., 0., 1., 2., 1.],\n",
            "        [2., 0., 0., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 2., 1., 2.],\n",
            "        [2., 1., 0., 1., 0., 0., 2., 1., 0.],\n",
            "        [1., 0., 0., 1., 1., 0., 1., 0., 2.],\n",
            "        [0., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
            "        [1., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
            "        [1., 1., 0., 1., 2., 2., 0., 0., 0.],\n",
            "        [2., 1., 1., 0., 0., 0., 0., 2., 1.],\n",
            "        [1., 0., 0., 1., 1., 2., 0., 0., 1.],\n",
            "        [1., 0., 1., 2., 1., 0., 1., 0., 0.],\n",
            "        [1., 0., 0., 2., 0., 1., 2., 0., 1.],\n",
            "        [0., 0., 1., 1., 0., 0., 0., 1., 1.],\n",
            "        [0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
            "        [0., 2., 1., 1., 0., 1., 0., 2., 0.],\n",
            "        [1., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 1.],\n",
            "        [0., 1., 0., 1., 0., 0., 0., 1., 1.],\n",
            "        [0., 1., 0., 0., 1., 1., 2., 1., 0.],\n",
            "        [0., 2., 1., 0., 1., 2., 1., 0., 2.],\n",
            "        [2., 2., 1., 0., 1., 0., 1., 2., 0.],\n",
            "        [0., 1., 2., 1., 0., 2., 1., 0., 0.],\n",
            "        [1., 0., 0., 2., 0., 1., 0., 1., 2.],\n",
            "        [1., 1., 1., 0., 1., 0., 0., 2., 0.],\n",
            "        [1., 2., 1., 0., 0., 1., 0., 0., 1.],\n",
            "        [0., 2., 1., 0., 0., 1., 1., 0., 1.],\n",
            "        [1., 0., 1., 2., 1., 0., 0., 0., 1.],\n",
            "        [0., 1., 1., 0., 1., 2., 1., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 1., 1., 0., 1.],\n",
            "        [0., 0., 1., 1., 1., 0., 0., 1., 0.]])\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "{'input_data': [[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ezkl==2.5.0"
      ],
      "metadata": {
        "id": "cVKOwNkeVS_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286d0e54-d43e-4c7b-b625-b7b0ff3b3b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ezkl==2.5.0 in /usr/local/lib/python3.10/dist-packages (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ezkl\n",
        "\n",
        "data_path = os.path.join(\"data.json\")\n",
        "calibration_path = os.path.join(\"cal_data.json\")\n",
        "model_path = os.path.join('tictactoe_network.onnx')\n",
        "compiled_model_path = os.path.join('network.compiled')\n",
        "pk_path = os.path.join('test.pk')\n",
        "vk_path = os.path.join('test.vk')\n",
        "settings_path = os.path.join('settings.json')\n",
        "srs_path = os.path.join('kzg.srs')\n",
        "witness_path = os.path.join('witness.json')"
      ],
      "metadata": {
        "id": "XciCNe7FuJrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = ezkl.gen_settings(model_path, settings_path)\n"
      ],
      "metadata": {
        "id": "vhuNewTIt_Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = await ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n"
      ],
      "metadata": {
        "id": "IJdL0ywquSa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
        "assert res == True"
      ],
      "metadata": {
        "id": "Pxr8u1NrxJ6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = ezkl.get_srs(srs_path, settings_path)\n"
      ],
      "metadata": {
        "id": "jCnJ-SV0xVrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
        "assert os.path.isfile(witness_path)"
      ],
      "metadata": {
        "id": "e5Wem6vsxYqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = ezkl.mock(witness_path, compiled_model_path)\n",
        "assert res == True"
      ],
      "metadata": {
        "id": "88bQephvxcM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = ezkl.setup(\n",
        "        compiled_model_path,\n",
        "        vk_path,\n",
        "        pk_path,\n",
        "        srs_path,\n",
        "    )\n",
        "\n",
        "assert res == True\n",
        "assert os.path.isfile(vk_path)\n",
        "assert os.path.isfile(pk_path)\n",
        "assert os.path.isfile(settings_path)"
      ],
      "metadata": {
        "id": "VSo9lFeDPRRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proof_path = os.path.join('test.pf')\n",
        "\n",
        "res = ezkl.prove(\n",
        "        witness_path,\n",
        "        compiled_model_path,\n",
        "        pk_path,\n",
        "        proof_path,\n",
        "        srs_path,\n",
        "        \"single\",\n",
        "    )\n",
        "\n",
        "print(res)\n",
        "assert os.path.isfile(proof_path)"
      ],
      "metadata": {
        "id": "CScshU1sPTj1",
        "outputId": "95ad7601-0349-4663-b22b-2e23856dab34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instances': [[[0, 0, 0, 0], [6930022730485989170, 11978191471204854555, 12639325020136072457, 1101375913260555885], [2380092094745148954, 12498903388508146745, 1701137478841417509, 2419297115035005132]]], 'proof': '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', 'transcript_type': 'EVM'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERIFY IT\n",
        "res = ezkl.verify(\n",
        "        proof_path,\n",
        "        settings_path,\n",
        "        vk_path,\n",
        "        srs_path,\n",
        "    )\n",
        "\n",
        "assert res == True\n",
        "print(\"verified\")"
      ],
      "metadata": {
        "id": "ITuSThGPPVKd",
        "outputId": "d1d9e903-ef00-49bf-e4e4-9217cbf6b144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PA-Pn-k7PXDV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}